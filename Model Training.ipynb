{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch.optim as optim\n",
    "\n",
    "from Model import *\n",
    "from Preprocessing import *\n",
    "from sklearn.metrics import classification_report\n",
    "from torch.utils.data import DataLoader\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = pd.read_csv('data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>female</th>\n",
       "      <th>male</th>\n",
       "      <th>C</th>\n",
       "      <th>Q</th>\n",
       "      <th>S</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.530377</td>\n",
       "      <td>0.432793</td>\n",
       "      <td>-0.473674</td>\n",
       "      <td>-0.502445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.571831</td>\n",
       "      <td>0.432793</td>\n",
       "      <td>-0.473674</td>\n",
       "      <td>0.786845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.254825</td>\n",
       "      <td>-0.474545</td>\n",
       "      <td>-0.473674</td>\n",
       "      <td>-0.488854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.365167</td>\n",
       "      <td>0.432793</td>\n",
       "      <td>-0.473674</td>\n",
       "      <td>0.420730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.365167</td>\n",
       "      <td>-0.474545</td>\n",
       "      <td>-0.473674</td>\n",
       "      <td>-0.486337</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     1    2    3  female  male    C    Q    S       Age     SibSp     Parch  \\\n",
       "0  0.0  0.0  1.0     0.0   1.0  0.0  0.0  1.0 -0.530377  0.432793 -0.473674   \n",
       "1  1.0  0.0  0.0     1.0   0.0  1.0  0.0  0.0  0.571831  0.432793 -0.473674   \n",
       "2  0.0  0.0  1.0     1.0   0.0  0.0  0.0  1.0 -0.254825 -0.474545 -0.473674   \n",
       "3  1.0  0.0  0.0     1.0   0.0  0.0  0.0  1.0  0.365167  0.432793 -0.473674   \n",
       "4  0.0  0.0  1.0     0.0   1.0  0.0  0.0  1.0  0.365167 -0.474545 -0.473674   \n",
       "\n",
       "       Fare  \n",
       "0 -0.502445  \n",
       "1  0.786845  \n",
       "2 -0.488854  \n",
       "3  0.420730  \n",
       "4 -0.486337  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_data = ['Pclass', 'Sex', 'Embarked']\n",
    "numerical_data = ['Age', 'SibSp', 'Parch', 'Fare']\n",
    "labels = 'Survived'\n",
    "\n",
    "preproc = Preprocessor(raw_data, categorical_data, numerical_data, labels)\n",
    "preproc.X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = preproc.get_splits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparams\n",
    "params = {'batch size': 64,\n",
    "          'epochs': 100}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = trainData(torch.FloatTensor(X_train.values), \n",
    "                       torch.FloatTensor(y_train.values))\n",
    "test_data = testData(torch.FloatTensor(X_test.values))\n",
    "\n",
    "train_loader = DataLoader(dataset=train_data, batch_size=params['batch size'], shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_data, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001: | Loss: 0.83697 | Acc: 56.667\n",
      "Epoch 002: | Loss: 0.82314 | Acc: 61.333\n",
      "Epoch 003: | Loss: 0.83221 | Acc: 63.250\n",
      "Epoch 004: | Loss: 0.82002 | Acc: 66.750\n",
      "Epoch 005: | Loss: 0.80904 | Acc: 64.250\n",
      "Epoch 006: | Loss: 0.79812 | Acc: 69.500\n",
      "Epoch 007: | Loss: 0.79765 | Acc: 66.583\n",
      "Epoch 008: | Loss: 0.80128 | Acc: 66.917\n",
      "Epoch 009: | Loss: 0.76953 | Acc: 72.583\n",
      "Epoch 010: | Loss: 0.77449 | Acc: 71.167\n",
      "Epoch 011: | Loss: 0.74033 | Acc: 73.833\n",
      "Epoch 012: | Loss: 0.75703 | Acc: 73.417\n",
      "Epoch 013: | Loss: 0.73762 | Acc: 75.000\n",
      "Epoch 014: | Loss: 0.71691 | Acc: 76.083\n",
      "Epoch 015: | Loss: 0.71159 | Acc: 74.500\n",
      "Epoch 016: | Loss: 0.71134 | Acc: 74.583\n",
      "Epoch 017: | Loss: 0.68478 | Acc: 75.750\n",
      "Epoch 018: | Loss: 0.66277 | Acc: 78.083\n",
      "Epoch 019: | Loss: 0.69889 | Acc: 75.083\n",
      "Epoch 020: | Loss: 0.67029 | Acc: 76.500\n",
      "Epoch 021: | Loss: 0.66440 | Acc: 76.750\n",
      "Epoch 022: | Loss: 0.66569 | Acc: 76.083\n",
      "Epoch 023: | Loss: 0.63673 | Acc: 78.167\n",
      "Epoch 024: | Loss: 0.64100 | Acc: 77.167\n",
      "Epoch 025: | Loss: 0.63463 | Acc: 75.917\n",
      "Epoch 026: | Loss: 0.63750 | Acc: 75.750\n",
      "Epoch 027: | Loss: 0.61578 | Acc: 78.833\n",
      "Epoch 028: | Loss: 0.64244 | Acc: 77.583\n",
      "Epoch 029: | Loss: 0.61799 | Acc: 79.083\n",
      "Epoch 030: | Loss: 0.63016 | Acc: 77.417\n",
      "Epoch 031: | Loss: 0.61923 | Acc: 78.417\n",
      "Epoch 032: | Loss: 0.64372 | Acc: 77.417\n",
      "Epoch 033: | Loss: 0.58502 | Acc: 81.667\n",
      "Epoch 034: | Loss: 0.60666 | Acc: 79.750\n",
      "Epoch 035: | Loss: 0.60448 | Acc: 76.250\n",
      "Epoch 036: | Loss: 0.59831 | Acc: 79.333\n",
      "Epoch 037: | Loss: 0.59690 | Acc: 79.417\n",
      "Epoch 038: | Loss: 0.63150 | Acc: 77.250\n",
      "Epoch 039: | Loss: 0.58712 | Acc: 79.750\n",
      "Epoch 040: | Loss: 0.61235 | Acc: 78.917\n",
      "Epoch 041: | Loss: 0.62713 | Acc: 77.833\n",
      "Epoch 042: | Loss: 0.55899 | Acc: 81.667\n",
      "Epoch 043: | Loss: 0.61183 | Acc: 79.500\n",
      "Epoch 044: | Loss: 0.61955 | Acc: 77.333\n",
      "Epoch 045: | Loss: 0.58299 | Acc: 79.250\n",
      "Epoch 046: | Loss: 0.60617 | Acc: 79.833\n",
      "Epoch 047: | Loss: 0.58021 | Acc: 80.083\n",
      "Epoch 048: | Loss: 0.57815 | Acc: 81.333\n",
      "Epoch 049: | Loss: 0.58156 | Acc: 80.250\n",
      "Epoch 050: | Loss: 0.60511 | Acc: 78.917\n",
      "Epoch 051: | Loss: 0.58583 | Acc: 81.083\n",
      "Epoch 052: | Loss: 0.58139 | Acc: 81.000\n",
      "Epoch 053: | Loss: 0.59271 | Acc: 78.667\n",
      "Epoch 054: | Loss: 0.59302 | Acc: 80.500\n",
      "Epoch 055: | Loss: 0.58566 | Acc: 78.750\n",
      "Epoch 056: | Loss: 0.56945 | Acc: 80.250\n",
      "Epoch 057: | Loss: 0.56259 | Acc: 81.000\n",
      "Epoch 058: | Loss: 0.59392 | Acc: 79.583\n",
      "Epoch 059: | Loss: 0.59604 | Acc: 79.333\n",
      "Epoch 060: | Loss: 0.57977 | Acc: 80.167\n",
      "Epoch 061: | Loss: 0.59730 | Acc: 79.250\n",
      "Epoch 062: | Loss: 0.56048 | Acc: 80.750\n",
      "Epoch 063: | Loss: 0.55138 | Acc: 82.000\n",
      "Epoch 064: | Loss: 0.55963 | Acc: 80.833\n",
      "Epoch 065: | Loss: 0.60170 | Acc: 79.583\n",
      "Epoch 066: | Loss: 0.54525 | Acc: 81.667\n",
      "Epoch 067: | Loss: 0.56586 | Acc: 80.917\n",
      "Epoch 068: | Loss: 0.55285 | Acc: 80.667\n",
      "Epoch 069: | Loss: 0.56618 | Acc: 82.000\n",
      "Epoch 070: | Loss: 0.52694 | Acc: 82.833\n",
      "Epoch 071: | Loss: 0.56442 | Acc: 81.583\n",
      "Epoch 072: | Loss: 0.57947 | Acc: 80.083\n",
      "Epoch 073: | Loss: 0.57927 | Acc: 80.583\n",
      "Epoch 074: | Loss: 0.54317 | Acc: 82.167\n",
      "Epoch 075: | Loss: 0.56901 | Acc: 79.250\n",
      "Epoch 076: | Loss: 0.53942 | Acc: 81.250\n",
      "Epoch 077: | Loss: 0.57912 | Acc: 79.583\n",
      "Epoch 078: | Loss: 0.61221 | Acc: 79.167\n",
      "Epoch 079: | Loss: 0.57613 | Acc: 79.583\n",
      "Epoch 080: | Loss: 0.54725 | Acc: 81.417\n",
      "Epoch 081: | Loss: 0.59955 | Acc: 78.500\n",
      "Epoch 082: | Loss: 0.59006 | Acc: 81.000\n",
      "Epoch 083: | Loss: 0.55461 | Acc: 81.917\n",
      "Epoch 084: | Loss: 0.55174 | Acc: 80.417\n",
      "Epoch 085: | Loss: 0.54979 | Acc: 80.250\n",
      "Epoch 086: | Loss: 0.56775 | Acc: 80.583\n",
      "Epoch 087: | Loss: 0.56584 | Acc: 80.833\n",
      "Epoch 088: | Loss: 0.57727 | Acc: 80.833\n",
      "Epoch 089: | Loss: 0.59970 | Acc: 79.250\n",
      "Epoch 090: | Loss: 0.59300 | Acc: 81.667\n",
      "Epoch 091: | Loss: 0.56266 | Acc: 80.500\n",
      "Epoch 092: | Loss: 0.56213 | Acc: 80.083\n",
      "Epoch 093: | Loss: 0.53540 | Acc: 82.083\n",
      "Epoch 094: | Loss: 0.54064 | Acc: 83.417\n",
      "Epoch 095: | Loss: 0.53217 | Acc: 82.083\n",
      "Epoch 096: | Loss: 0.56186 | Acc: 80.833\n",
      "Epoch 097: | Loss: 0.60184 | Acc: 77.500\n",
      "Epoch 098: | Loss: 0.55822 | Acc: 80.500\n",
      "Epoch 099: | Loss: 0.58500 | Acc: 78.583\n",
      "Epoch 100: | Loss: 0.51766 | Acc: 83.333\n"
     ]
    }
   ],
   "source": [
    "model = MLP()\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=preproc.pos_weight)\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "model, loss_data, acc_data = train(model, criterion, optimizer, train_loader, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.89      0.87       110\n",
      "           1       0.81      0.74      0.77        69\n",
      "\n",
      "    accuracy                           0.83       179\n",
      "   macro avg       0.83      0.82      0.82       179\n",
      "weighted avg       0.83      0.83      0.83       179\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = gen_predictions(model, test_loader)\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train on all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = trainData(torch.FloatTensor(preproc.X.values), \n",
    "                       torch.FloatTensor(preproc.y.values))\n",
    "train_loader = DataLoader(dataset=train_data, batch_size=params['batch size'], shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001: | Loss: 0.83816 | Acc: 52.929\n",
      "Epoch 002: | Loss: 0.79662 | Acc: 61.714\n",
      "Epoch 003: | Loss: 0.77052 | Acc: 70.143\n",
      "Epoch 004: | Loss: 0.75275 | Acc: 71.929\n",
      "Epoch 005: | Loss: 0.73942 | Acc: 74.214\n",
      "Epoch 006: | Loss: 0.72929 | Acc: 75.643\n",
      "Epoch 007: | Loss: 0.72098 | Acc: 76.143\n",
      "Epoch 008: | Loss: 0.70530 | Acc: 76.929\n",
      "Epoch 009: | Loss: 0.69688 | Acc: 77.857\n",
      "Epoch 010: | Loss: 0.68381 | Acc: 78.429\n",
      "Epoch 011: | Loss: 0.67286 | Acc: 78.643\n",
      "Epoch 012: | Loss: 0.66183 | Acc: 77.571\n",
      "Epoch 013: | Loss: 0.65514 | Acc: 77.714\n",
      "Epoch 014: | Loss: 0.65175 | Acc: 78.143\n",
      "Epoch 015: | Loss: 0.62221 | Acc: 81.500\n",
      "Epoch 016: | Loss: 0.61997 | Acc: 78.857\n",
      "Epoch 017: | Loss: 0.61920 | Acc: 79.929\n",
      "Epoch 018: | Loss: 0.62770 | Acc: 79.571\n",
      "Epoch 019: | Loss: 0.61506 | Acc: 78.786\n",
      "Epoch 020: | Loss: 0.61173 | Acc: 80.500\n",
      "Epoch 021: | Loss: 0.60573 | Acc: 79.571\n",
      "Epoch 022: | Loss: 0.60194 | Acc: 79.143\n",
      "Epoch 023: | Loss: 0.59160 | Acc: 79.214\n",
      "Epoch 024: | Loss: 0.59786 | Acc: 80.000\n",
      "Epoch 025: | Loss: 0.60819 | Acc: 78.571\n",
      "Epoch 026: | Loss: 0.59489 | Acc: 80.857\n",
      "Epoch 027: | Loss: 0.57004 | Acc: 80.429\n",
      "Epoch 028: | Loss: 0.58853 | Acc: 80.071\n",
      "Epoch 029: | Loss: 0.56259 | Acc: 80.786\n",
      "Epoch 030: | Loss: 0.57064 | Acc: 81.357\n",
      "Epoch 031: | Loss: 0.55367 | Acc: 81.357\n",
      "Epoch 032: | Loss: 0.56916 | Acc: 80.786\n",
      "Epoch 033: | Loss: 0.55359 | Acc: 81.071\n",
      "Epoch 034: | Loss: 0.57498 | Acc: 80.071\n",
      "Epoch 035: | Loss: 0.55080 | Acc: 80.857\n",
      "Epoch 036: | Loss: 0.56360 | Acc: 81.071\n",
      "Epoch 037: | Loss: 0.55979 | Acc: 80.286\n",
      "Epoch 038: | Loss: 0.55924 | Acc: 80.643\n",
      "Epoch 039: | Loss: 0.54428 | Acc: 82.429\n",
      "Epoch 040: | Loss: 0.56560 | Acc: 81.214\n",
      "Epoch 041: | Loss: 0.55734 | Acc: 81.214\n",
      "Epoch 042: | Loss: 0.55835 | Acc: 80.000\n",
      "Epoch 043: | Loss: 0.57408 | Acc: 81.429\n",
      "Epoch 044: | Loss: 0.55728 | Acc: 80.429\n",
      "Epoch 045: | Loss: 0.55069 | Acc: 81.286\n",
      "Epoch 046: | Loss: 0.53096 | Acc: 81.929\n",
      "Epoch 047: | Loss: 0.54808 | Acc: 81.714\n",
      "Epoch 048: | Loss: 0.54702 | Acc: 81.000\n",
      "Epoch 049: | Loss: 0.54541 | Acc: 81.286\n",
      "Epoch 050: | Loss: 0.55284 | Acc: 80.929\n",
      "Epoch 051: | Loss: 0.53129 | Acc: 82.143\n",
      "Epoch 052: | Loss: 0.53510 | Acc: 82.143\n",
      "Epoch 053: | Loss: 0.53845 | Acc: 80.786\n",
      "Epoch 054: | Loss: 0.54050 | Acc: 81.714\n",
      "Epoch 055: | Loss: 0.52641 | Acc: 82.071\n",
      "Epoch 056: | Loss: 0.54735 | Acc: 82.214\n",
      "Epoch 057: | Loss: 0.54855 | Acc: 82.286\n",
      "Epoch 058: | Loss: 0.55691 | Acc: 81.929\n",
      "Epoch 059: | Loss: 0.53752 | Acc: 81.786\n",
      "Epoch 060: | Loss: 0.53479 | Acc: 82.071\n",
      "Epoch 061: | Loss: 0.54097 | Acc: 82.643\n",
      "Epoch 062: | Loss: 0.54830 | Acc: 81.643\n",
      "Epoch 063: | Loss: 0.53733 | Acc: 81.857\n",
      "Epoch 064: | Loss: 0.54106 | Acc: 82.214\n",
      "Epoch 065: | Loss: 0.53937 | Acc: 80.929\n",
      "Epoch 066: | Loss: 0.52557 | Acc: 82.286\n",
      "Epoch 067: | Loss: 0.52832 | Acc: 81.500\n",
      "Epoch 068: | Loss: 0.52895 | Acc: 82.286\n",
      "Epoch 069: | Loss: 0.54063 | Acc: 81.357\n",
      "Epoch 070: | Loss: 0.53925 | Acc: 82.214\n",
      "Epoch 071: | Loss: 0.52264 | Acc: 82.786\n",
      "Epoch 072: | Loss: 0.53004 | Acc: 82.643\n",
      "Epoch 073: | Loss: 0.52914 | Acc: 82.857\n",
      "Epoch 074: | Loss: 0.52902 | Acc: 83.000\n",
      "Epoch 075: | Loss: 0.53456 | Acc: 82.071\n",
      "Epoch 076: | Loss: 0.53147 | Acc: 82.714\n",
      "Epoch 077: | Loss: 0.52928 | Acc: 81.929\n",
      "Epoch 078: | Loss: 0.54970 | Acc: 81.000\n",
      "Epoch 079: | Loss: 0.51817 | Acc: 81.786\n",
      "Epoch 080: | Loss: 0.51728 | Acc: 83.214\n",
      "Epoch 081: | Loss: 0.51804 | Acc: 82.643\n",
      "Epoch 082: | Loss: 0.52342 | Acc: 82.500\n",
      "Epoch 083: | Loss: 0.53426 | Acc: 81.357\n",
      "Epoch 084: | Loss: 0.52104 | Acc: 82.429\n",
      "Epoch 085: | Loss: 0.51910 | Acc: 82.357\n",
      "Epoch 086: | Loss: 0.53560 | Acc: 82.214\n",
      "Epoch 087: | Loss: 0.51650 | Acc: 82.786\n",
      "Epoch 088: | Loss: 0.51976 | Acc: 82.786\n",
      "Epoch 089: | Loss: 0.53589 | Acc: 81.643\n",
      "Epoch 090: | Loss: 0.51098 | Acc: 82.214\n",
      "Epoch 091: | Loss: 0.52446 | Acc: 82.429\n",
      "Epoch 092: | Loss: 0.53549 | Acc: 82.000\n",
      "Epoch 093: | Loss: 0.52227 | Acc: 82.786\n",
      "Epoch 094: | Loss: 0.52920 | Acc: 81.786\n",
      "Epoch 095: | Loss: 0.51949 | Acc: 82.857\n",
      "Epoch 096: | Loss: 0.52177 | Acc: 83.500\n",
      "Epoch 097: | Loss: 0.54105 | Acc: 80.929\n",
      "Epoch 098: | Loss: 0.51525 | Acc: 82.500\n",
      "Epoch 099: | Loss: 0.51373 | Acc: 82.286\n",
      "Epoch 100: | Loss: 0.51531 | Acc: 81.714\n"
     ]
    }
   ],
   "source": [
    "model = MLP()\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=preproc.pos_weight)\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "model, loss_data, acc_data = train(model, criterion, optimizer, train_loader, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>3</td>\n",
       "      <td>Kelly, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330911</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n",
       "      <td>female</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>363272</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>2</td>\n",
       "      <td>Myles, Mr. Thomas Francis</td>\n",
       "      <td>male</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>240276</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>3</td>\n",
       "      <td>Wirz, Mr. Albert</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>315154</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>3</td>\n",
       "      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3101298</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass                                          Name     Sex  \\\n",
       "0          892       3                              Kelly, Mr. James    male   \n",
       "1          893       3              Wilkes, Mrs. James (Ellen Needs)  female   \n",
       "2          894       2                     Myles, Mr. Thomas Francis    male   \n",
       "3          895       3                              Wirz, Mr. Albert    male   \n",
       "4          896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female   \n",
       "\n",
       "    Age  SibSp  Parch   Ticket     Fare Cabin Embarked  \n",
       "0  34.5      0      0   330911   7.8292   NaN        Q  \n",
       "1  47.0      1      0   363272   7.0000   NaN        S  \n",
       "2  62.0      0      0   240276   9.6875   NaN        Q  \n",
       "3  27.0      0      0   315154   8.6625   NaN        S  \n",
       "4  22.0      1      1  3101298  12.2875   NaN        S  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get predictions for the real test set\n",
    "raw_test_data = pd.read_csv('data/test.csv')\n",
    "raw_test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preproc = Preprocessor(raw_test_data, categorical_data,\n",
    "                            numerical_data, weight=preproc.pos_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>female</th>\n",
       "      <th>male</th>\n",
       "      <th>C</th>\n",
       "      <th>Q</th>\n",
       "      <th>S</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.298549</td>\n",
       "      <td>-0.499470</td>\n",
       "      <td>-0.400248</td>\n",
       "      <td>-0.497811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.181328</td>\n",
       "      <td>0.616992</td>\n",
       "      <td>-0.400248</td>\n",
       "      <td>-0.512660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.240662</td>\n",
       "      <td>-0.499470</td>\n",
       "      <td>-0.400248</td>\n",
       "      <td>-0.464532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.231118</td>\n",
       "      <td>-0.499470</td>\n",
       "      <td>-0.400248</td>\n",
       "      <td>-0.482888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.584229</td>\n",
       "      <td>0.616992</td>\n",
       "      <td>0.619896</td>\n",
       "      <td>-0.417971</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     1    2    3  female  male    C    Q    S       Age     SibSp     Parch  \\\n",
       "0  0.0  0.0  1.0     0.0   1.0  0.0  1.0  0.0  0.298549 -0.499470 -0.400248   \n",
       "1  0.0  0.0  1.0     1.0   0.0  0.0  0.0  1.0  1.181328  0.616992 -0.400248   \n",
       "2  0.0  1.0  0.0     0.0   1.0  0.0  1.0  0.0  2.240662 -0.499470 -0.400248   \n",
       "3  0.0  0.0  1.0     0.0   1.0  0.0  0.0  1.0 -0.231118 -0.499470 -0.400248   \n",
       "4  0.0  0.0  1.0     1.0   0.0  0.0  0.0  1.0 -0.584229  0.616992  0.619896   \n",
       "\n",
       "       Fare  \n",
       "0 -0.497811  \n",
       "1 -0.512660  \n",
       "2 -0.464532  \n",
       "3 -0.482888  \n",
       "4 -0.417971  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_preproc.X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = testData(torch.FloatTensor(test_preproc.X.values))\n",
    "test_loader = DataLoader(dataset=test_data, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = gen_predictions(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#format for submission\n",
    "pred_df = pd.DataFrame(columns=['Survived'], data=predictions)\n",
    "submission_df = pd.concat([raw_test_data['PassengerId'], pred_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId    int64\n",
       "Survived       int32\n",
       "dtype: object"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_df.head()\n",
    "submission_df = submission_df.astype({'Survived': 'int32'})\n",
    "submission_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df.to_csv('data/submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "check = pd.read_csv('data/submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId    int64\n",
       "Survived       int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
